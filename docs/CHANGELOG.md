# Changelog

## [2.0.0] - 2025-11-28

### Added
- âœ¨ **Auto-select mode**: Tá»± Ä‘á»™ng so sÃ¡nh ML vs Rule-based vÃ  chá»n cháº¿ Ä‘á»™ tá»‘t nháº¥t
- ğŸ¤– **ML-based gesture recognition**: Support 3 models (Random Forest, SVM, MLP)
- ğŸ“Š **Multi-model training**: Train táº¥t cáº£ models vÃ  auto-select model tá»‘t nháº¥t
- ğŸ”„ **Dual-mode system**: ML-based (95%+) vÃ  Rule-based (78%) vá»›i toggle 'M'
- ğŸ“ **Auto data collection**: Automated training data collection
- ğŸ¯ **Model comparison tool**: So sÃ¡nh accuracy giá»¯a cÃ¡c modes
- âš™ï¸ **Config persistence**: LÆ°u selected mode vÃ o model_config.json
- ğŸ“ **Comprehensive documentation**: AUTO_SELECT_GUIDE.md, TRAINING_GUIDE.md

### Changed
- ğŸ”§ Simplified project structure (removed redundant files)
- ğŸ“¦ Updated README.md - ngáº¯n gá»n, dá»… hiá»ƒu hÆ¡n
- ğŸ¨ Improved .gitignore
- ğŸ“‹ Better requirements.txt with comments

### Fixed
- âœ… Volume gesture detection (thumb LEFT + finger spread/close)
- âœ… Next_video gesture (4 fingers, exclude thumb)
- âœ… ML model loading vá»›i auto-detect
- âœ… Metadata JSON serialization
- âœ… Dynamic class handling trong training

### Removed
- âŒ run_ml.py, run_rulebased.py (consolidated into run.py)
- âŒ train_workflow.py (redundant)
- âŒ quick_compare.py (integrated into auto_select_mode.py)

## [1.0.0] - Initial Release

### Features
- Basic hand tracking vá»›i MediaPipe
- Rule-based gesture detection
- Mouse control (moving, clicking)
- Video control (forward, backward)
- Volume control
- Next video navigation
